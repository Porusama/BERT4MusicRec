# Bert4MusicRec
Нейросетевой алгоритм генерации музыкальных пользовательских рекомендаций, основанный на BERT4Rec архитектуре.
Демо-версия для локального запуска.


## Воспроизводимость и ограничения
Репозиторий содержит:
- оригинальный код, охватывающий весь пайплайн;
- оригинальную конфигурации нейросети;
- оригинальные архитектурные решения отраженные в коде.

Весь код написан в тесной интеграции с PostgreSQL, сильно завязан на модели данных, поэтому полное воспроизведение алгоритма подразумевает наличие доступа к этой БД, использование данных необходимой структуры.
В связи с этим в репозитории лежит демо-датасет и демо-последовательность для быстрого воспроизведения процессов обучения, валидации и инференса модели. 

Репозиторий не содержит:
- оригинальный датасет (вес ~ 1.6 GB);
- данные для подключения к СУБД;
- sql-файлы с запросами к БД.

Подробнее о содержании ниже.

## Установка и запуск
1. Клонирование репозитория

```bash
git clone https://github.com/Porusama/BERT4MusicRec
```

2. Установка зависимостей  
Основное необходимое ПО: Python v3.13.1, pip v25.2, Jupyter Notebook v7.3.2  
Не гарантируется, что скрипты отработают на более старших версиях.  
Необходимые Python модули можно установить командой из папки с репозиторием:

```bash
pip install -r requirements.txt
```

**Опционально**: Установить CUDA, cudnn, pytorch+cuda для GPU обработки, если устройство поддерижвает.  
CUDA:           (https://developer.nvidia.com/cuda-toolkit)  
cudnn:          (https://developer.nvidia.com/cudnn)  
pytorch+cuda:   (https://pytorch.org/get-started/locally/)  

В requirments.txt указана версия torch>=2.6.0, что является нейтральной записью. Подойдет и для CPU исполнения.

3. Запуск демонстрационного Jupyter-блокнота

```bash
cd <репозиторий>
jupyter notebook
```
Исполнение ячеек последовательно.

## Содержание репозитория
Ниже представлено дерево файлов и папок с описаниями

```bash
.
├─ demo data/   — Демонстрационные данные
│  │
│  ├─ name.csv      — Названия песен, артистов, альбомов из sample.csv
│  ├─ sample.csv    — Случайная выборка из 3000 последовательностей оригинального датасета
│  └─ sequence.csv  — Последовательность для рекомендации
│
├─ preprocessing encoders/ — Предобучнные модели для кодировки
│  │
│  ├─ label_encoder_albums.pkl      — Кодировщик айди альбомов
│  ├─ label_encoder_artists.pkl     — Кодировщик айди авртистов
│  ├─ label_encoder_songs.pkl       — Кодировщик айди песен
│  ├─ one_hot_encoder.pkl           — Унитарный кодировщик характеристики тактового размера
│  └─ standart_scaler.pkl           — Скейлер числовых хар-к
│
├─ config.py                — Конфигурция модели и обучения
├─ dataset.py               — Имплементация torch.utils.data.Dataset (Загрузка данных в модель, разделение на батчи)  
├─ demo.ipynb               — Jupyter блокнот с демо обучением, валидацией, генерацией рекомендаций
├─ flask_app.py             — Микросервис, принимающий запросы от СУБД в локальной сети. Рекомендует.
├─ model.py                 — Архитектура модели на torch.nn
├─ preprocessing_utils.py   — Утилиты для предобработки
├─ preprocessing.py         — Получение данных из СУБД, предобработка и сохранение в csv
├─ train.py                 — Цикл обучения модели
├─ requirements.txt         — Необходимые python модули
├─ README.md
└─ .gitignore
```

Названия создаваемых при обучении папок и файлов заданы в config.py, также в нем задается размерность модели.  
В случае, если исполнение демонстрационного Jupyter-блокнота занимает много времени, рекомендуется понизить параметры:  
_seq_len_,  _d_song_, _d_albums_, _d_artists_, _d_ff_, _N_, _heads_.  
Описание этих и прочих гиперпараметров представлено в самом файле.